# 📚 동화책 전체 스토리 TTS 생성 기능 회의록

---

## 🧪 1차 시도: 음성 클로닝 기반 TTS

- **목표**: 부모님의 목소리를 클로닝하여 동화를 낭독하게 함
- **도구**: Coqui TTS
- **진행**:
  - 다수의 음성 샘플을 평균화하여 음성 임베딩 생성
  - 최초 임베딩 후 캐시로 속도 개선
- **문제점**:
  - GPU 없이 처리 속도 매우 느림
  - 고품질 한국어 낭독 위해 추가 학습 필요 → 현실적으로 어려움
  - 소스 녹음 조건(무잡음, 명료한 발음, 30초 이상 x 5개)이 까다로움
- **결론**: 현실적인 제약으로 클로닝 방식 중단

---

## 🔁 2차 시도: 클로닝 포기 → 생동감 있는 TTS 집중

- **TTS**: Naver Clova Voice
- **감정 분석**: Clova Studio (Playground)
- **전략**:
  - Clova Studio로 감정 분석 후 낭독 설정 추출(JSON)
  - Clova Voice로 감정 반영된 낭독 수행
- **문제점**:
  - Clova Studio Playground API 사용 시 토큰 소모 심각
- **결론**: 유지비 부담으로 이 방식도 중단

---

## 🧠 3차 시도: Google Cloud TTS + Gemini 감정 분석

- **TTS**: Google Cloud Text-to-Speech (SSML 지원)
- **감정 분석**: Google Gemini
- **전략**:
  - Gemini → 감정 분석 → SSML 태그 생성 → GCP TTS 전달
- **결과**:
  - 감정 분석 정확도 좋고 비용도 낮음
  - 그러나 GCP TTS의 한국어 발음 품질 낮아 사용 불가

---

## ✅ 4차 시도: Clova Voice + Gemini 감정 분석 (최종 채택)

- **TTS**: Naver Clova Voice
- **감정 분석**: Google Gemini
- **전략**:
  - Gemini가 문장별 감정/화자/속도/톤/볼륨 등 분석
  - Clova Voice TTS에 전달 → 감정 낭독
- **결과**:
  - 자연스럽고 감정적인 한국어 음성 생성
  - 비용과 품질 모두 만족 → **최종 선택**

---

## 📈 전체 TTS 기능 흐름

1. **사용자 로그인**
   - JWT 인증
   - 로그인 유저의 `user_id` → 관련 `story_id` 확보

2. **동화 본문 불러오기**
   - `paragraph_no` 1~10 (또는 11~20) 기준으로 본문 로딩

3. **문장 분리**
   - `kss` 사용 → 문장 단위 분리 (내레이션/대사 포함)

4. **감정 분석**
   - Google Gemini → 각 문장 감정/화자/속도 분석

5. **TTS 생성**
   - Clova Voice에 분석 결과를 바탕으로 문장별 합성

6. **음원 병합**
   - `pydub`으로 문장별 음원을 병합
   - 병합 파일 저장 + 문단별로도 분할 저장

---

## 🎧 추가 기능: AI 질문 스트리밍 TTS

- **목적**: 동화 중간 삽입 질문(ai_question)을 실시간 낭독
- **방식**:
  1. 유저 인증 확인
  2. `qa_id`로 DB 조회
  3. 질문 텍스트 → Clova Voice TTS
  4. `StreamingHttpResponse`로 실시간 전달

---

## 🎧 추가 기능: 문단별 TTS 생성 기능

- **목적**: 전체 오디오 생성 시 문단 단위로 오디오 파일도 저장
- **방식**:
  1. 전체 문장을 문단별로 분리
  2. 문장 단위 TTS 생성 → 개별 음성 길이 측정
  3. 각 문단에 포함된 문장의 음성 길이 합으로 오프셋 계산
  4. 병합된 전체 오디오에서 각 문단의 구간만 잘라 별도 mp3 저장
  5. 시행착오: 각 문장의 오디오를 생성한후 합쳐서 전체파일을 만드는 방식  
     - 제미나이 감정과 화자가 일관성을 상실하는 문제  
     - 문단 매핑과정에서 분절된 단어와 문장의 순서가 뒤섞이는 문제  

