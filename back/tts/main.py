# back/tts/main.py
import os
import time
from .utils.text_processor import split_text_into_sentences
from .utils.text_ana_gen import analyze_texts_with_gemini
from .utils.clova_tts import synthesize_clova_tts
from pydub import AudioSegment

def build_final_audio(text, save_path, gemini_api_key, clova_client_id, clova_client_secret, character_list=""):
    """
    ì „ì²´ í…ìŠ¤íŠ¸ ì…ë ¥ â†’ ë¬¸ë‹¨ë³„ ë¬¸ì¥ ë¶„ë¦¬ â†’ ê°ì • ë¶„ì„ â†’ TTS ìƒì„±
    â†’ ë³‘í•© ì €ì¥ (userID_storyID_all.mp3) â†’ ë¬¸ë‹¨ë³„ ì¶”ì¶œ (userID_storyID_paragraph_x.mp3) â†’ ì„ì‹œíŒŒì¼ ì‚­ì œ
    """
    total_start = time.time()

    # ì‚¬ìš©ì ë° ìŠ¤í† ë¦¬ ID ì¶”ì¶œ
    base_dir = os.path.dirname(save_path)
    filename = os.path.splitext(os.path.basename(save_path))[0]
    file_prefix = filename if not filename.endswith("_all") else filename[:-4]  

    all_audio_path = os.path.join(base_dir, f"{file_prefix}_all.mp3")

    # ì´ë¯¸ ìƒì„±ëœ ì „ì²´ íŒŒì¼ì´ ìˆë‹¤ë©´ ì¬ì‚¬ìš©
    if os.path.exists(all_audio_path):
        print(f"âš ï¸ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” íŒŒì¼: {all_audio_path} â†’ ì¬ìƒì„± ìƒëµ")
        paragraph_paths = {}
        for i in range(10):
            para_path = os.path.join(base_dir, f"{file_prefix}_paragraph_{i + 11}.mp3")
            if os.path.exists(para_path):
                paragraph_paths[i + 11] = para_path
        return all_audio_path, paragraph_paths

    # ë¬¸ë‹¨ë³„ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    paragraphs = text.strip().split("\n")

    # ë¬¸ë‹¨ë³„ ë¬¸ì¥ ë¶„ë¦¬ 
    paragraph_sentence_map = []
    for para in paragraphs:
        sentence_list = split_text_into_sentences(para)
        paragraph_sentence_map.append(sentence_list)

    # ì „ì²´ ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸ + ë¬¸ë‹¨ë³„ ì¸ë±ìŠ¤ ë²”ìœ„ ìƒì„±
    all_sentences = []
    index_ranges = []
    cursor = 0
    for sents in paragraph_sentence_map:
        all_sentences.extend(sents)
        index_ranges.append(list(range(cursor, cursor + len(sents))))
        cursor += len(sents)

    print(f"âœ… ì „ì²´ ë¬¸ì¥ ìˆ˜: {len(all_sentences)}")

    print("ğŸ” ê°ì • ë¶„ì„ ì¤‘...")
    configs = analyze_texts_with_gemini(
        all_sentences,
        api_key=gemini_api_key,
        characters=character_list
    )

    print("ğŸ™ï¸ TTS í•©ì„± ì‹œì‘...")
    temp_dir = os.path.join(base_dir, "_segments")
    os.makedirs(temp_dir, exist_ok=True)

    segment_files = []
    durations = []

    for i, cfg in enumerate(configs):
        temp_path = os.path.join(temp_dir, f"seg_{i+1}.wav")
        print(f"   - [{i+1}] speaker={cfg['speaker']}, emotion={cfg['emotion']}")

        success = synthesize_clova_tts(
            text=cfg["sentence"],
            speaker=cfg["speaker"],
            emotion=cfg["emotion"],
            emotion_strength=cfg["emotion_strength"],
            pitch=cfg["pitch"],
            speed=cfg["speed"],
            volume=cfg["volume"],
            output_path=temp_path,
            client_id=clova_client_id,
            client_secret=clova_client_secret
        )
        if success:
            segment_files.append(temp_path)
            durations.append(len(AudioSegment.from_wav(temp_path)))

    if not segment_files:
        print("âŒ TTS í•©ì„±ì— ì„±ê³µí•œ íŒŒì¼ì´ ì—†ì–´ ë³‘í•©ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return False

    # ë³‘í•©
    print("ğŸ§ ìŒì„± ë³‘í•© ì¤‘...")
    segments = [AudioSegment.from_wav(f) for f in segment_files]
    combined = sum(segments[1:], segments[0])
    combined.export(all_audio_path, format="mp3")
    audio_merge_end = time.time()
    print(f"âœ… ë³‘í•© ì™„ë£Œ ë° {all_audio_path} ì €ì¥")

    # Offset ê³„ì‚°
    offsets = []
    current_offset = 0
    for dur in durations:
        offsets.append((current_offset, current_offset + dur))
        current_offset += dur

    # ë¬¸ë‹¨ ë²ˆí˜¸ 1~10ì— ë§¤í•‘
    full_audio = AudioSegment.from_mp3(all_audio_path)
    paragraph_paths = {}

    for i, idx_range in enumerate(index_ranges, start=1):
        para_path = os.path.join(base_dir, f"{file_prefix}_paragraph_{i}.mp3")
        if os.path.exists(para_path):
            print(f"â© ë¬¸ë‹¨ {i} íŒŒì¼ ì¡´ì¬í•¨ â†’ ê±´ë„ˆëœ€")
            paragraph_paths[i] = para_path
            continue

        start = offsets[idx_range[0]][0]
        end = offsets[idx_range[-1]][1]
        segment = full_audio[start:end]
        segment.export(para_path, format="mp3")
        paragraph_paths[i] = para_path

    segment_split_end = time.time()

    # ì„ì‹œíŒŒì¼ ì‚­ì œ
    for f in segment_files:
        try:
            os.remove(f)
        except OSError as e:
            print(f"âš ï¸ ì„ì‹œíŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e.filename} - {e.strerror}")
    try:
        os.rmdir(temp_dir)
    except OSError:
        pass

    print(f"âœ… ìµœì¢… ì €ì¥ ì™„ë£Œ: {all_audio_path}")
    print(f"â±ï¸ ì „ì²´ ë³‘í•© ì‹œê°„: {round(audio_merge_end - total_start, 2)}ì´ˆ")
    print(f"â±ï¸ ë¬¸ë‹¨ë³„ ë¶„í•  ì‹œê°„: {round(segment_split_end - audio_merge_end, 2)}ì´ˆ")
    print(f"â±ï¸ ì´ ì†Œìš” ì‹œê°„: {round(segment_split_end - total_start, 2)}ì´ˆ")

    return all_audio_path, paragraph_paths
